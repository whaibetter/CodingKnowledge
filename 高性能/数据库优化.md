# 数据库优化

// TODO

## 读写分离

### [什么是读写分离？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#什么是读写分离)

- 将读写操作分离在不同的节点上

  - 小幅度提升写性能，大幅度提升读性能。
  - 主库写，从库读，同步

  ![读写分离示意图](http://42.192.130.83:9000/picgo/imgs/read-and-write-separation.png)

  

### [如何实现读写分离？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#如何实现读写分离)

1. 多个数据库
2. 主从复制
3. 写请求给主库

#### 1. 基于代理

在应用和数据中间加了一个代理层

> 提供类似功能的中间件有 **MySQL Router**（官方， MySQL Proxy 的替代方案）、**Atlas**（基于 MySQL Proxy）、**MaxScale**、**MyCat**。

![代理方式实现读写分离](http://42.192.130.83:9000/picgo/imgs/read-and-write-separation-proxy.png)

#### **2. 组件方式**

在这种方式中，我们可以通过引入第三方组件来帮助我们读写请求。

这也是我比较推荐的一种方式。这种方式目前在各种互联网公司中用的最多的，相关的实际的案例也非常多。如果你要采用这种方式的话，推荐使用 `sharding-jdbc` ，直接引入 jar 包即可使用，非常方便。同时，也节省了很多运维的成本。

你可以在 shardingsphere 官方找到 [sharding-jdbc 关于读写分离的操作open in new window](https://shardingsphere.apache.org/document/legacy/3.x/document/cn/manual/sharding-jdbc/usage/read-write-splitting/)。



### 主从复制原理是什么？

- **MySQL binlog(binary log 即二进制日志文件)** 主要记录了 MySQL 数据库中数据的所有变化(数据库执行的**所有 DDL 和 DML 语句**)

  - 基于**MySQL binlog** 日志就能够将主库的数据同步到从库中。

  > 1. 主库将数据库中数据的变化**写入到 binlog**
  > 2. 从库连接主库
  > 3. 从库会**创建一个 I/O 线程向主库请求更新的 binlog**
  > 4. 主库会**创建一个 binlog dump 线程来发送 binlog** ，从库中的 I/O 线程负责接收
  > 5. 从库的 **I/O 线程将接收的 binlog 写入到 relay log 中**。
  > 6. 从库的 **SQL 线程读取 relay log 同步数据本地**（也就是**再执行一遍** SQL）。

**MySQL 主从复制是依赖于 binlog 。另外，常见的一些同步 MySQL 数据到其他数据源的工具（比如 canal）的底层一般也是依赖 binlog 。**

### [如何避免主从延迟？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#如何避免主从延迟)

无法容忍延迟？

#### 1. 强制读取主库

比如 `Sharding-JDBC` 就是采用的这种方案。通过使用 Sharding-JDBC 的 `HintManager` 分片键值管理器，我们可以强制使用主库。

```java
HintManager hintManager = HintManager.getInstance();
hintManager.setMasterRouteOnly();
// 继续JDBC操作
```

对于这种方案，你可以将那些必须获取最新数据的读请求都交给主库处理。

#### 2. 延迟读取，等同步完了

- 也就在需要支付等业务的时候可能有用。

### [什么情况下会出现主从延迟？如何尽量减少延迟？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#什么情况下会出现主从延迟-如何尽量减少延迟)

- 主从复制的原理入手

> `主库写入 binlog --------网络传输速度----->从库 I/O 线程读取速度-------SQL执行速度------->SQL执行relay log速度`
>
> 1. 主库写入binlog
>
> 2. 从库I/O线程接收太慢
>
>    生产者： 主库写入 binlog 的速度
>
>    消费者：从库 I/O 线程读取速度
>
> 3. 从库SQL执行relay log速度太慢
>
>    生产者：从库 I/O 线程读取速度
>
>    消费者：SQL执行relay log速度

#### 出现情况

1. **从库机器性能比主库差**
2. **从库处理的读请求过多**
3. **大事务**：运行时间比较长，长时间未提交的事务就可以称为大事务。由于大事务执行时间长，并且从库上的大事务会比主库上的大事务花费更多的时间和资源，因此非常容易造成主从延迟。解决办法是避免大批量修改数据，尽量分批进行。类似的情况还有执行时间较长的慢 SQL ，实际项目遇到慢 SQL 应该进行优化。
4. **从库太多**
5. **网络延迟**
6. **单线程复制**：MySQL5.5 及之前，只支持单线程复制。为了优化复制性能，MySQL 5.6 引入了 **多线程复制**，MySQL 5.7 还进一步完善了多线程复制。
7. **复制模式**：MySQL 默认的复制是异步的，必然会存在延迟问题。全同步复制不存在延迟问题，但性能太差了。半同步复制是一种折中方案，相对于异步复制，半同步复制提高了数据的安全性，减少了主从延迟（还是有一定程度的延迟）。MySQL 5.5 开始，MySQL 以插件的形式支持 **semi-sync 半同步复制**。并且，MySQL 5.7 引入了 **增强半同步复制** 。

## [分库分表](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#分库分表)

### [什么是分库？什么是垂直、水平分库？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#什么是分库)

- 把数据分散到不同的库中
- **垂直分库**：**不同业务分**配到不同的库中。用户表；订单表；
- **水平分库**：同一个表划分到不同数据库，订单表1；订单表2；

### [什么是分表？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#什么是分表)

- 把数据表拆分
- **垂直分表**：对数据列拆分，如用户表单独拆分出几个列为一个新表。
- **水平分表：**将一个表根据规则划分为两个表存储，订单表1，订单表2；

### [什么情况下需要分库分表？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#什么情况下需要分库分表)

1. 并发量太大
2. 表太大，读取很慢了
3. 占用空间太大

### [常见的分片算法有哪些？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#常见的分片算法有哪些)

解决存储在哪的问题？

1. 哈希 如Hash（id）
2. 范围 如0-1000，1000-2000
3. 地理位置
4. 融合算法（结合多种）

### [分库分表会带来什么问题呢？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#分库分表会带来什么问题呢)

1. **join操作**	

   但不建议使用join（效率低），会对分库分表造成影响

   可以多次查询后在业务层组装

2. **事务**

   引入分布式事务

3. **id的生成**

   不能自增了，使用分布式id来生成id。

   > [分库分表的 9种分布式主键ID 生成方案，挺全乎的-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1745072)
   >
   > - **UUID** 字符串没有丝毫的意义，存储性能差而且耗时
   > - **数据库自增ID** 单独一个实例生成ID
   > - **数据库多主模式** 1357 2468
   > - 号段模式
   > - Redis
   > - **雪花算法**（SnowFlake）
   > - 滴滴出品（TinyID）区域+业务+数据库的一张表
   > - 百度 （Uidgenerator）id划分+雪花
   > - 美团（Leaf）区域+业务+雪花

4. **聚合查询**

    group by，order by 等变得异常复杂。为了实现这些操作，需要编写复杂的业务代码，或者使用中间件来协调分片间的通信和数据传输。

### id的生成算法？

- **UUID**  128位的唯一标识符；由于索引是按照值的顺序进行组织和存储的，UUID 的随机性会导致索引的分布不均匀，从而可能影响查询性能。

- **SNOWFLAKE**  Twitter开源的由64位整数，在分布式系统中产生**全局唯一**且**趋势递增**的ID。

  - 符号位置1bit、时间戳41bit、机器id（数据中心id 5bit+机器id 5bit）、序列号 12bit

    ```
    0|0000000000 0000000000 0000000000 0000000000 0|00000|00000|000000000000
    ```

  - 特点：严重依赖于[服务器](https://cloud.tencent.com/act/pro/promotion-cvm?from_column=20065&from=20065)时间、服务器**时钟回拨**会导致产生重复的 ID（**就是时间不一致的问题，ntp调整时间后可能变早了**）

- `segment`号段：需要id的时候去要号段，号1001-2000就是你的了，用完再去要下一个号段。





### [分库分表有没有什么比较推荐的方案？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#分库分表有没有什么比较推荐的方案)

> Apache ShardingSphere 是一款分布式的数据库生态系统， 可以将任意数据库转换为分布式数据库，并通过数据分片、弹性伸缩、加密等能力对原有数据库进行增强。
>
> ShardingSphere 项目（包括 Sharding-JDBC、Sharding-Proxy 和 Sharding-Sidecar）是当当捐入 Apache 的，目前主要由京东数科的一些巨佬维护。
>
> ShardingSphere 绝对可以说是当前分库分表的首选！ShardingSphere 的功能完善，除了支持读写分离和分库分表，还提供分布式事务、数据库治理、影子库、数据加密和脱敏等功能。
>
> ShardingSphere 提供的功能如下：
>
> ![ShardingSphere 提供的功能](http://42.192.130.83:9000/picgo/imgs/shardingsphere-features.png)
>
> ShardingSphere 的优势如下（摘自 ShardingSphere 官方文档：[https://shardingsphere.apache.org/document/current/cn/overview/open in new window](https://shardingsphere.apache.org/document/current/cn/overview/)）：
>
> - 极致性能：驱动程序端历经长年打磨，效率接近原生 JDBC，性能极致。
> - 生态兼容：代理端支持任何通过 MySQL/PostgreSQL 协议的应用访问，驱动程序端可对接任意实现 JDBC 规范的数据库。
> - 业务零侵入：面对数据库替换场景，ShardingSphere 可满足业务无需改造，实现平滑业务迁移。
> - 运维低成本：在保留原技术栈不变前提下，对 DBA 学习、管理成本低，交互友好。
> - 安全稳定：基于成熟数据库底座之上提供增量能力，兼顾安全性及稳定性。
> - 弹性扩展：具备计算、存储平滑在线扩展能力，可满足业务多变的需求。
> - 开放生态：通过多层次（内核、功能、生态）插件化能力，为用户提供可定制满足自身特殊需求的独有系统。
>
> 另外，ShardingSphere 的生态体系完善，社区活跃，文档完善，更新和发布比较频繁。
>
> 不过，还是要多提一句：**现在很多公司都是用的类似于 TiDB 这种分布式关系型数据库，不需要我们手动进行分库分表（数据库层面已经帮我们做了），也不需要解决手动分库分表引入的各种问题，直接一步到位，内置很多实用的功能（如无感扩容和缩容、冷热存储分离）！如果公司条件允许的话，个人也是比较推荐这种方式！

### [分库分表后，数据怎么迁移呢？](https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#分库分表后-数据怎么迁移呢)

1. **停机迁移**，写个脚本老库的数据写到新库中。

2. **双写方案**

   - 对老库**修改，同时要写入新库**。（操作不在新库，就插入到新库）可以保证新库最新。
   - 还需要自己写脚本将老库中的**数据和新库的数据做比对（校准）**。

   想要在项目中实施双写还是比较麻烦的，很容易会出现问题。我们可以借助上面提到的数据库同步工具 Canal 做增量数据迁移（还是依赖 binlog，开发和维护成本较低）